{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau,Callback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Nadam, RMSprop\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D,Flatten,Dense,Dropout,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "import keras.backend as K\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "x_train = np.load('/Users/levsvalov/code_workspace/Fall2020/ML/Project/input_data/x.npy')\n",
    "y_train = np.load('/Users/levsvalov/code_workspace/Fall2020/ML/Project/input_data/y.npy')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# one hot encode outputs - do not work\n",
    "# y_train = np_utils.to_categorical(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    m = Sequential()\n",
    "    m.add(Conv2D(8,kernel_size=5,input_shape=(28,28,1),activation='relu')) # one aaron ramsey\n",
    "    m.add(MaxPool2D(pool_size=2,strides=1))\n",
    "    m.add(Conv2D(12,kernel_size=3,input_shape=(28,28,1),activation='relu')) # ooolivierr giroud\n",
    "    m.add(MaxPool2D(pool_size=2))\n",
    "    m.add(Conv2D(34,kernel_size=3,input_shape=(28,28,1),activation='relu')) # ee granit xhaka\n",
    "    m.add(MaxPool2D(pool_size=2,strides=1))\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Flatten())\n",
    "    m.add(Dense(86,activation='relu')) # kuch\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Dropout(0.2))\n",
    "    m.add(Dense(134,activation='relu'))\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Dropout(0.2))\n",
    "    m.add(Dense(92,activation='relu')) # kuzy\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Dropout(0.2))\n",
    "    m.add(Dense(10,activation='softmax'))\n",
    "    return m"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:337: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/usr/local/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/usr/local/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:739: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/34\n",
      "391/390 - 44s - loss: 1.0132 - accuracy: 0.6707 - val_loss: 0.4945 - val_accuracy: 0.8476\n",
      "Epoch 2/34\n",
      "391/390 - 45s - loss: 0.4089 - accuracy: 0.8749 - val_loss: 0.3272 - val_accuracy: 0.8985\n",
      "Epoch 3/34\n",
      "391/390 - 45s - loss: 0.3029 - accuracy: 0.9089 - val_loss: 0.2040 - val_accuracy: 0.9377\n",
      "Epoch 4/34\n",
      "391/390 - 45s - loss: 0.2522 - accuracy: 0.9235 - val_loss: 0.1766 - val_accuracy: 0.9481\n",
      "Epoch 5/34\n",
      "391/390 - 45s - loss: 0.2236 - accuracy: 0.9331 - val_loss: 0.1526 - val_accuracy: 0.9508\n",
      "Epoch 6/34\n",
      "391/390 - 45s - loss: 0.2011 - accuracy: 0.9399 - val_loss: 0.1545 - val_accuracy: 0.9520\n",
      "Epoch 7/34\n",
      "391/390 - 44s - loss: 0.1860 - accuracy: 0.9432 - val_loss: 0.1469 - val_accuracy: 0.9515\n",
      "Epoch 8/34\n",
      "391/390 - 45s - loss: 0.1791 - accuracy: 0.9464 - val_loss: 0.1316 - val_accuracy: 0.9575\n",
      "Epoch 9/34\n",
      "391/390 - 44s - loss: 0.1687 - accuracy: 0.9489 - val_loss: 0.1283 - val_accuracy: 0.9596\n",
      "Epoch 10/34\n",
      "391/390 - 44s - loss: 0.1588 - accuracy: 0.9518 - val_loss: 0.1479 - val_accuracy: 0.9565\n",
      "Epoch 11/34\n",
      "391/390 - 43s - loss: 0.1575 - accuracy: 0.9531 - val_loss: 0.1462 - val_accuracy: 0.9524\n",
      "Epoch 12/34\n",
      "391/390 - 43s - loss: 0.1515 - accuracy: 0.9543 - val_loss: 0.1141 - val_accuracy: 0.9652\n",
      "Epoch 13/34\n",
      "391/390 - 42s - loss: 0.1487 - accuracy: 0.9555 - val_loss: 0.1151 - val_accuracy: 0.9644\n",
      "Epoch 14/34\n",
      "391/390 - 42s - loss: 0.1405 - accuracy: 0.9577 - val_loss: 0.0987 - val_accuracy: 0.9697\n",
      "Epoch 15/34\n",
      "391/390 - 43s - loss: 0.1393 - accuracy: 0.9588 - val_loss: 0.1417 - val_accuracy: 0.9577\n",
      "Epoch 16/34\n",
      "391/390 - 42s - loss: 0.1365 - accuracy: 0.9602 - val_loss: 0.1027 - val_accuracy: 0.9665\n",
      "Epoch 17/34\n",
      "391/390 - 42s - loss: 0.1339 - accuracy: 0.9608 - val_loss: 0.1061 - val_accuracy: 0.9680\n",
      "Epoch 18/34\n",
      "391/390 - 42s - loss: 0.1299 - accuracy: 0.9617 - val_loss: 0.1091 - val_accuracy: 0.9679\n",
      "Epoch 19/34\n",
      "391/390 - 42s - loss: 0.1279 - accuracy: 0.9627 - val_loss: 0.0902 - val_accuracy: 0.9707\n",
      "Epoch 20/34\n",
      "391/390 - 42s - loss: 0.1258 - accuracy: 0.9631 - val_loss: 0.1038 - val_accuracy: 0.9675\n",
      "Epoch 21/34\n",
      "391/390 - 42s - loss: 0.1220 - accuracy: 0.9635 - val_loss: 0.0959 - val_accuracy: 0.9705\n",
      "Epoch 22/34\n",
      "391/390 - 42s - loss: 0.1214 - accuracy: 0.9638 - val_loss: 0.0902 - val_accuracy: 0.9704\n",
      "Epoch 23/34\n",
      "391/390 - 42s - loss: 0.1182 - accuracy: 0.9660 - val_loss: 0.0782 - val_accuracy: 0.9737\n",
      "Epoch 24/34\n",
      "391/390 - 42s - loss: 0.1194 - accuracy: 0.9645 - val_loss: 0.0884 - val_accuracy: 0.9733\n",
      "Epoch 25/34\n",
      "391/390 - 42s - loss: 0.1171 - accuracy: 0.9653 - val_loss: 0.0802 - val_accuracy: 0.9768\n",
      "Epoch 26/34\n",
      "391/390 - 42s - loss: 0.1191 - accuracy: 0.9646 - val_loss: 0.0758 - val_accuracy: 0.9773\n",
      "Epoch 27/34\n",
      "391/390 - 42s - loss: 0.1141 - accuracy: 0.9661 - val_loss: 0.0906 - val_accuracy: 0.9713\n",
      "Epoch 28/34\n",
      "391/390 - 42s - loss: 0.1117 - accuracy: 0.9673 - val_loss: 0.0909 - val_accuracy: 0.9705\n",
      "Epoch 29/34\n",
      "391/390 - 42s - loss: 0.1120 - accuracy: 0.9671 - val_loss: 0.0734 - val_accuracy: 0.9757\n",
      "Epoch 30/34\n",
      "391/390 - 42s - loss: 0.1094 - accuracy: 0.9679 - val_loss: 0.0991 - val_accuracy: 0.9687\n",
      "Epoch 31/34\n",
      "391/390 - 42s - loss: 0.1086 - accuracy: 0.9676 - val_loss: 0.0773 - val_accuracy: 0.9753\n",
      "Epoch 32/34\n",
      "391/390 - 42s - loss: 0.1054 - accuracy: 0.9693 - val_loss: 0.0893 - val_accuracy: 0.9724\n",
      "Epoch 33/34\n",
      "391/390 - 42s - loss: 0.1086 - accuracy: 0.9682 - val_loss: 0.0863 - val_accuracy: 0.9725\n",
      "Epoch 34/34\n",
      "391/390 - 42s - loss: 0.1053 - accuracy: 0.9697 - val_loss: 0.0937 - val_accuracy: 0.9713\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x14178a090>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reverse color\n",
    "# rescale image in ove\n",
    "model = make_model()\n",
    "#83:\n",
    "generator = ImageDataGenerator(zca_whitening=True,rotation_range=35, width_shift_range=0.15,height_shift_range=0.15,brightness_range=[0.2,0.8],zoom_range=0.25,validation_split=0.15)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy',factor=0.25,patience=8)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "model.compile(optimizer=Nadam(1e-3,clipnorm=1),loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(generator.flow(x_train,y_train, batch_size=128),\n",
    "          validation_data=generator.flow(x_train,y_train, batch_size=128,subset='validation'),\n",
    "          epochs=34,verbose=2,callbacks=[early_stopping,lr_scheduler],\n",
    "          steps_per_epoch=(len(x_train)/128)) #david luiz eee zhi\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "model.save('/Users/levsvalov/code_workspace/Fall2020/ML/Project/model.h5')\n",
    "print(\"done\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}